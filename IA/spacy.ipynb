{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyttsx3\n",
      "  Downloading pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
      "Collecting comtypes (from pyttsx3)\n",
      "  Downloading comtypes-1.2.0-py2.py3-none-any.whl (184 kB)\n",
      "                                              0.0/184.3 kB ? eta -:--:--\n",
      "     -----------------                        81.9/184.3 kB ? eta -:--:--\n",
      "     -----------------------------------    174.1/184.3 kB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 184.3/184.3 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting pypiwin32 (from pyttsx3)\n",
      "  Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\suporte\\appdata\\roaming\\python\\python311\\site-packages (from pyttsx3) (306)\n",
      "Installing collected packages: comtypes, pypiwin32, pyttsx3\n",
      "Successfully installed comtypes-1.2.0 pypiwin32-223 pyttsx3-2.90\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_PT-BR_MARIA_11.0\n",
      "Name: Microsoft Maria Desktop - Portuguese(Brazil)\n",
      "Languages: []\n",
      "Gender: None\n",
      "-----\n",
      "ID: HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_ZIRA_11.0\n",
      "Name: Microsoft Zira Desktop - English (United States)\n",
      "Languages: []\n",
      "Gender: None\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "\n",
    "# Criação do objeto de fala\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define a configuração da voz (opcional)\n",
    "voices = engine.getProperty('voices')\n",
    "\n",
    "# Definir idioma para o português do Brasil\n",
    "engine.setProperty('voice', 'pt-br')\n",
    "\n",
    "# Imprime as informações de cada voz\n",
    "for voice in voices:\n",
    "    print(\"ID:\", voice.id)\n",
    "    print(\"Name:\", voice.name)\n",
    "    print(\"Languages:\", voice.languages)\n",
    "    print(\"Gender:\", voice.gender)\n",
    "    print(\"-----\")\n",
    "\n",
    "\n",
    "\n",
    "engine.setProperty('voice', voices[0].id)  # Seleciona a primeira voz disponível\n",
    "\n",
    "# Texto que será reproduzido\n",
    "texto = \"Teste de output de voz!\"\n",
    "\n",
    "# Reproduz o texto em fala\n",
    "engine.say(texto)\n",
    "#engine.save_to_file(texto, \"nao_atenda_encrenca.mp3\")\n",
    "engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O spaCy é uma ótima biblioteca para PLN em português.\n",
      "Palavra: O, Parte da Fala: DET, Lemma: o\n",
      "Palavra: spaCy, Parte da Fala: NOUN, Lemma: spaCy\n",
      "Palavra: é, Parte da Fala: AUX, Lemma: ser\n",
      "Palavra: uma, Parte da Fala: DET, Lemma: um\n",
      "Palavra: ótima, Parte da Fala: ADJ, Lemma: ótimo\n",
      "Palavra: biblioteca, Parte da Fala: NOUN, Lemma: biblioteca\n",
      "Palavra: para, Parte da Fala: ADP, Lemma: para\n",
      "Palavra: PLN, Parte da Fala: PROPN, Lemma: PLN\n",
      "Palavra: em, Parte da Fala: ADP, Lemma: em\n",
      "Palavra: português, Parte da Fala: NOUN, Lemma: português\n",
      "Palavra: ., Parte da Fala: PUNCT, Lemma: .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pyttsx3\n",
    "\n",
    "# Carregue o modelo de linguagem pré-treinado em português\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "# Texto de exemplo para análise\n",
    "texto = \"O spaCy é uma ótima biblioteca para PLN em português.\"\n",
    "\n",
    "# Processar o texto usando o modelo carregado\n",
    "doc = nlp(texto)\n",
    "\n",
    "# Iterar pelas palavras no texto\n",
    "for token in doc:\n",
    "    print(f\"Palavra: {token.text}, Parte da Fala: {token.pos_}, Lemma: {token.lemma_}\")\n",
    "\n",
    "'''\n",
    "Este script em Python utiliza a biblioteca spaCy para realizar o processamento de linguagem natural (PLN) em texto em português. \n",
    "\n",
    "1. `import spacy`: Esta linha importa a biblioteca spaCy, que é uma biblioteca popular para \n",
    "]processamento de linguagem natural em várias línguas, incluindo o português.\n",
    "\n",
    "2. `nlp = spacy.load(\"pt_core_news_sm\")`: Aqui, um modelo de linguagem pré-treinado em português é carregado usando o spaCy. \n",
    "O modelo \"pt_core_news_sm\" é uma versão menor e mais rápida do modelo de processamento de linguagem natural para o português.\n",
    "\n",
    "3. `texto = \"O spaCy é uma ótima biblioteca para PLN em português.\"`: Esta linha define um exemplo de texto \n",
    "que será processado pelo spaCy. No caso, o texto é \"O spaCy é uma ótima biblioteca para PLN em português.\"\n",
    "\n",
    "4. `doc = nlp(texto)`: Aqui, o texto definido anteriormente é processado pelo modelo de linguagem carregado. \n",
    "O resultado é armazenado na variável `doc`, que se torna um objeto que contém as informações linguísticas do texto processado.\n",
    "\n",
    "5. `for token in doc:`: Isso inicia um loop que percorrerá cada \"token\" no texto processado. \n",
    "Um token é uma unidade de texto, geralmente uma palavra ou parte dela.\n",
    "\n",
    "6. `print(f\"Palavra: {token.text}, Parte da Fala: {token.pos_}, Lemma: {token.lemma_}\")`: \n",
    "Dentro do loop, para cada token no texto, o script imprime informações linguísticas sobre o token. As informações impressas incluem:\n",
    "   - `token.text`: A própria palavra ou parte dela.\n",
    "   - `token.pos_`: A parte da fala (classe gramatical) do token, como substantivo, verbo, adjetivo, etc.\n",
    "   - `token.lemma_`: O lemma do token, que é a forma base da palavra. Por exemplo, o lemma de \"correndo\" é \"correr\".\n",
    "\n",
    "No final, o script percorrerá todas as palavras do texto de exemplo e imprimirá suas palavras, partes da fala e lemmas. \n",
    "Isso é útil para análise linguística e processamento de texto em tarefas de PLN.\n",
    "'''\n",
    "\n",
    "\n",
    "# Criação do objeto de fala\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define a configuração da voz (opcional)\n",
    "voices = engine.getProperty('voices')\n",
    "\n",
    "# Definir idioma para o português do Brasil\n",
    "engine.setProperty('voice', 'pt-br')\n",
    "\n",
    "# Reproduz o texto em fala\n",
    "engine.say(texto)\n",
    "#engine.save_to_file(texto, \"nao_atenda_encrenca.mp3\")\n",
    "engine.runAndWait()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
